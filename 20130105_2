import nltk
import cPickle
#words = cPickle.load(open("myData.pickle"))
freq_dist = nltk.FreqDist(words)
freq_dist.keys()[:50]




import re
rt_patterns = re.compile(r"(RT|via)((?:\b\W*@\w+)+)", re.IGNORECASE)        
example_tweets=["RT @SocialWebMining Justin Bieber is on SNL 2nite. w00t?!?",
... "Justin Bieber is on SNL 2nite. w00t?!? (via @SocialWebMining)"]
for t in example_tweets:
  rt_patterns.findall(t)


import networkx as nx
import re
g = nx.DiGraph()
all_tweets = [ tweet
  for page in search_results
    for tweet in page["results"]]

def get_rt_sources(tweet):
  rt_patterns = re.compile(r"(RT|via)((?:\b\W*@\w+)+)", re.IGNORECASE)
  return [source.strip()
    for tuple in rt_patterns.findall(tweet)
      for source in tuple
        if source not in ("RT", "via")]

for tweet in all_tweets:
  rt_sources = get_rt_sources(tweet["text"])
  if not rt_sources: continue
  for rt_source in rt_sources:
    g.add_edge(rt_source, tweet["from_user"], {"tweet_id" : tweet["id"]})


g.number_of_nodes()

g.number_of_edges()

g.edges(data=True)[0]

len(nx.connected_components(g.to_undirected()))

sorted(nx.degree(g).values())
